---
title: "Perceptron"
description: "A simple linear classifier trained with the perceptron rule."
---

# âš¡ Perceptron

<img src="../../images/supervised/perceptron.svg" alt="Perceptron icon" width="80" />

The perceptron learns a separating hyperplane by iteratively correcting mistakes on training samples.

## Hypothesis

For feature vector $\mathbf{x}$,

$$
\hat{y} = \text{sign}(\mathbf{w}^T \mathbf{x} + b).
$$

## Update Rule

When a sample $(\mathbf{x}^{(i)}, y^{(i)})$ is misclassified, the weights are updated as

$$
\mathbf{w} \leftarrow \mathbf{w} + y^{(i)} \mathbf{x}^{(i)}, \quad b \leftarrow b + y^{(i)}.
$$

## Example (scikit-learn)

```python
from sklearn.linear_model import Perceptron

X = [[0,0], [1,1], [1,0], [0,1]]
y = [0, 1, 1, 0]

model = Perceptron()
model.fit(X, y)

pred = model.predict([[1, 1]])
print(pred)
```

## Use Case Example

Early neural network for tasks like linearly separable image recognition.

## Recommendations

- Only converges if data are linearly separable.
- Consider using modern variants like SVM or logistic regression for better performance.
- See the [scikit-learn docs](https://scikit-learn.org/stable/modules/linear_model.html#perceptron) for details.
